{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 提出区分【d】深層学習_day4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section1: 強化学習\n",
    "#### 要点まとめ\n",
    "・教師あり学習、教師なし学習、強化学習の3つの分類がある<br>\n",
    "・強化学習:行動の結果として与えられる利益をもとに、行動を決定する。その原理を改善していく仕組み<br>\n",
    "・最初はランダムに動き、徐々にベターな行動を取るようにする。探索と利用のトレードオフ<br>\n",
    "・強化関数は計算量の問題があったが、関数近似法とQ学習を組み合わせる手法が登場し注目を集めた<br>\n",
    "・関数近似法は価値関数や方策関数を関数近似する手法のこと<br>\n",
    "・Q学習は行動価値関数を行動する毎に更新することにより学習を進める手法<br>\n",
    "・価値関数とは状態価値関数と行動価値関数(こっちがより重要。状態価値+方策を加味)の2種類がある<br>\n",
    "・方策関数とはある状態でどのような行動をとるのかの確率を与える関数。価値関数を最大にするような方策を取る<br>\n",
    "・方策勾配法<br>\n",
    "$θ^{(t+1)}=θ^{(t)}+ε∇J(θ)$<br>\n",
    "・上記式はNNの重みの更新式に似ている。NNは誤差を小さくしたかったが、強化学習では機体収益を大きくしたいので”＋”になっている<br>\n",
    "<img src=\"img/img1.png\" width=\"400\"><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section2: AlphaGo\n",
    "#### 要点まとめ\n",
    "・AlphaGo Lee:方策関数(PolicyNet)、行動価値関数(ValueNet)をNNで表現<br>\n",
    "・強化学習のステップ<br>\n",
    "(1)教師あり学習によるRollOutPolicy(NNではなく線形の方策関数で高速化)とPolicyNetを学習<br>\n",
    "(2)強化学習によるPolicyNetの学習<br>\n",
    "(3)強化学習によるValueNetの学習<br>\n",
    "<img src=\"img/img2.png\" width=\"500\"><br>\n",
    "・AlphaGo ZeroとAlphaGo Leeの違い<br>\n",
    "(1)教師あり学習を一切行わず、強化学習のみで作成<br>\n",
    "(2)ヒューリスティックな要素を排除し、石の配置のみにした<br>\n",
    "(3)PolicyNetとValueNetを一つのネットワークにした<br>\n",
    "(4)ResidualNet(中間層をショートカットするものを作ることで勾配消失を防ぐ)を導入した<br>\n",
    "(5)モンテカルロ木探索からRollOutシミュレーションをなくした<br>\n",
    "・NNは1つだが、方策関数の出力と行動価値関数の出力を別々に出力<br>\n",
    "<img src=\"img/img3.png\" width=\"500\"><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section3: 軽量化・高速化技術\n",
    "#### 要点まとめ\n",
    "●分散深層学習:複数の計算資源を使用し、並列的にニューラルネットワークを構成することで、効率の良い学習したい<br>\n",
    "(1)データの並列化<br>\n",
    "・データ並列化:CPUやGPUをワーカーとしてワーカー単位で並列化して処理する。データの更新は同期型と非同期型がある<br>\n",
    "・同期型:各モデルのパラメータを一旦親モデルに合わせてパラメータ更新をする<br>\n",
    "・非同期型:他のワーカーが計算を終えるのを待たない。学習データをパラメータサーバに保存する。同期型の方が精度は高く遅い<br>\n",
    "・自分たちのデータセンターがある場合等は同期型を採用し、分散並列をグローバルにやる場合は同期型にすることはできないので非同期型を採用する<br>\n",
    "(2)モデル並列化<br>\n",
    "・モデル並列化:1つの大きなモデルを細かいモデルに分割し、ワーカーに計算させる。1つのPCで並列化することが多い<br>\n",
    "(3)GPUによる高速技術を使用する<br>\n",
    "・GPUによる高速化:比較的低性能なコアが多数あり簡単な並列処理が得意<br>\n",
    "・GPGPUの開発環境:CUDA、OpenCLがあるがCUDAが主流。CUDAの使い方を覚える必要ななく、DLのフレームワークの使い方を覚えれば大丈夫<br>\n",
    "●軽量化:スマートフォン等でも計算できるように軽量化を行う<br>\n",
    "(1)量子化<br>\n",
    "・量子化:大量のメモリを必要とする重り等のパラメータを64bit浮動小数点から32bit等の下位の制度に落とすことでメモリと演算処理の削減を行う<br>\n",
    "・量子化の利点:省メモリ化、計算の高速化<br>\n",
    "・量子化の欠点:精度の低下<br>\n",
    "(2)蒸留<br>\n",
    "・規模の大きなモデルの知識を利用し軽量なモデルの作成を行う<br>\n",
    "・教師モデル(複雑なモデル)を用いて生徒モデル(軽量なモデル)を学習する。誤差はほぼ生徒モデルの誤差になり、教師モデルに近づくように生徒モデルを学習する<br>\n",
    "(3)プルーニング<br>\n",
    "・モデルの制度に寄与が少ないニューロンを削減することでモデルの軽量化、高速化を図る<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section4: 応用モデル\n",
    "#### 要点まとめ\n",
    "●MobileNets:画像認識ネットワーク<br>\n",
    "・Depthwise Convolution(フィルタ数1つ),Pointwise Convolution(フィルタサイズが1)を使用する<br>\n",
    "・普通の畳み込みの計算を分割することで計算量が削減される<br>\n",
    "<img src=\"img/img5.png\" width=\"400\"><br>\n",
    "●DenseNet:画像認識ネットワーク<br>\n",
    "・Dense Blockを使用する。チャネルが増えていくような構造<br>\n",
    "・DenseNetとResNetの違い<br>\n",
    "DenseBlockは前方の各層からの出力全てが広報の層への入力として用いられる<br>\n",
    "ResNetでは前1層の入力のみ後方の層へ入力<br>\n",
    "●BatchNorm:画像認識ネットワーク<br>\n",
    "・ミニバッチ単位で同一チャネルが同一分布に従うように正規化する<br>\n",
    "・問題点:バッチサイズに影響を受ける。バッチサイズは計算機に依存する<br>\n",
    "●LayerNorm:画像認識ネットワーク<br>\n",
    "・それぞれのsampleの全てのpixelsが同一分布に従うように正規化する<br>\n",
    "●InstancehNorm:画像認識ネットワーク<br>\n",
    "・チャネルも同一分布に従うように正規化する<br>\n",
    "●WaveNet:音声生成モデル<br>\n",
    "・畳み込みを用いた音声生成<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section5: Transformer\n",
    "#### 要点まとめ\n",
    "・ニューラル機械翻訳の問題点:翻訳元の文の内容を一つのベクトルで表現するため文長が長くなると表現力が足りなくなる<br>\n",
    "・Attention:翻訳先の各単語を選択する際に、翻訳元の文中の各単語に対して加重平均を取る。重要な単語には加重が高い<br>\n",
    "・Transformer:2017年に登場。RNNを使用せず、Attentionのみを用いる<br>\n",
    "・Self-Attention:文脈を反映した自己表現を得られる文脈依存のConvolution。CNNはウィンドウサイズがあるため、決められた範囲のConvolutionのみ行うが、Self-AttentionはInputされた全ての情報からそれぞれを定義していくので、ウィンドウサイズが文の長さのConvolutionと考えられる<br>\n",
    "<img src=\"img/img8.png\" width=\"400\"><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section6: 物体検知・セグメンテーション\n",
    "#### 要点まとめ\n",
    "●物体検知とセグメンテーション<br>\n",
    "・物体検知の出力:BoundingBox。どこに何があるかという情報<br>\n",
    "・セマンティックセグメンテーション:各ピクセルに対して単一のクラスラベル。例:背景と風船を区別<br>\n",
    "・インスタンスセグメンテーション:各ピクセルに対して単一のクラスラベル例：背景と風船を区別し、さらに風船同士も区別<br>\n",
    "●代表的なデータセット:学習させたい状況に応じてデータセットを選択する<br>\n",
    "・VOC12: クラスは20, Train+Valは11,540, 平均Box数2.4<br>\n",
    "・ILSVRC17: クラスは200, Train+Valは476,668,平均Box数1.1<br>\n",
    "・MS COCO18: クラスは80, Train+Valは123,287, 平均Box数7.3<br>\n",
    "・OICOD18: クラスは500, Train+Valは1,743,042, 平均Box数7.0<br>\n",
    "●評価<br>\n",
    "・物体検出では、クラスラベルだけでなく、物体位置の予測精度も評価したい<br>\n",
    "・IoU:Intersection over Union。IoUが0.8でも80%の精度とは言えない。例えば画像全体に予測BBを置いてしまうと100%となってしまう<br>\n",
    "<img src=\"img/img7.png\" width=\"200\"><br>\n",
    "・クラスラベルの閾値を変えるとPrecisionとRecallの結果は変わる。それを図示したものがAP曲線<br>\n",
    "$AP = \\int_{a}^{b}P(R)dR$<br>\n",
    "・クラス毎のAPが出る(人なら人)。全てのクラスのAPを平均したものがmAP(mean Average Precision)<br>\n",
    "$mAP=\\frac{1}{C}\\sum_{i=0}^{C}AP_i$<br>\n",
    "・IoUの閾値も変化させたものが$mAP_{coco}$->閾値を0.5から0.95まで0.05刻みでmAPを計算し、算術平均する<br>\n",
    "$mAP_{coco}=\\frac{mAP_{0.5}+mAP_{0.55}+…+mAP_{0.95}}{10}$<br>\n",
    "・検出速度:FPS(Flames per Second)<br>\n",
    "●物体検知の大枠<br>\n",
    "・物体検知のフレームワーク<br>\n",
    "２段階検出：候補領域の検出とクラス推定を別々に行う。精度が高い。計算量が多くなる。フレームワーク:RCNN,SPPNet,Fast RCCN, Faster RCNN, RFCN, FPN, Mask RCNN<br>\n",
    "1段階検出:候補領域の検出とクラス推定を同時に行う。精度が低い。計算量は小さい。フレームワーク:DetectorNet,SSD,YOLO,YOLO9000,RetinaNet,CornerNet<br>\n",
    "●SSD:Single Shot Detector<br>\n",
    "・画像に多数のDefault Boxを置き、SDDで学習しながらそのBOXを変形してconf.を出力する<br>\n",
    "・Non-Maximum Suppression:1つの物体に対して多数のBOXが割り当てられてしまうこと→IoUを計算して一番高いのだけ残すと良い<br>\n",
    "・Hard Negative Mining:背景クラスと非背景クラスの比率が多くなってしまう→背景クラスと非背景クラスを3:1程度にする<br>\n",
    "・DSSD:SSDのVGG16をResNetに変えたもの<br>\n",
    "●Semantic Segmentation<br>\n",
    "・ConvolutionやPoolingを繰り返すと入力画像の解像度が落ちていくため、落ちた解像度をどのようにして元に戻すのか、が問題となる<br>\n",
    "・Up-sampling:解像度をもととに戻す事<br>\n",
    "・Deconvolution/Transposed convolution<br>\n",
    "(1)特徴マップのpixel間隔をstrideだけ空ける<br>\n",
    "(2)特徴マップのまわりに(kernel size - 1) - paddingだけ余白を作る<br>\n",
    "(3)畳み込み演算を行う<br>\n",
    "・Dilated Convolution:Convolutionの段階で受容野を広げる工夫<br>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
